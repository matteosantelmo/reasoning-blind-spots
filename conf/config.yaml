defaults:
  - _self_

hydra:
  run:
    dir: outputs/${now:%Y-%m-%d_%H-%M-%S}

# Inspect AI evaluation settings
fail_on_error: false  # Fail on error: false for gentler handling of errors
retry_on_error: 2 # Retry on error: number of retries per sample failure
time_limit: 600 # Time limit per sample in seconds

dataset:
  # path: "data/ms_test.jsonl"
  path: "matsant01/blind-spots-bench"
  split: "test"
  limit: 3  # Limit the number of examples to evaluate (null for all)
  question_type:  # Which type/modality to include in the evaluation
  - text-only
  - multi-to-text
  - image-to-text

grader:
  enabled: true
  model_name: gemini-2.5-flash
  backend: google # openai | google | vllm
  generate_config:
    reasoning_tokens: -1  # (Gemini < 3) -1 for dynamic thinking budget; otherwise, number of thinking tokens
    reasoning_effort: null  # (OpenAI or Gemini >= 3) minimal | low | medium | high

solver:
  model_name: gemini-2.5-flash
  backend: google # openai | google | vllm

  generate_config:
    reasoning_tokens: 0  # (Gemini < 3) -1 for dynamic thinking budget; otherwise, number of thinking tokens
    reasoning_effort: null  # (OpenAI or Gemini >= 3) minimal | low | medium | high
