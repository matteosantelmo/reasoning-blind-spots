{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c4fd10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from inspect_ai.log import read_eval_log\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc3ec921",
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_df = pd.read_csv(\"../data/models_pricing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b15cf713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>input_price</th>\n",
       "      <th>output_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/gpt-oss-120b</td>\n",
       "      <td>LM</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MiniMaxAI/MiniMax-M2</td>\n",
       "      <td>LM</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.5162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek-ai/DeepSeek-V3.2</td>\n",
       "      <td>LM</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>1.8440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Qwen/Qwen3-VL-235B-A22B-Thinking</td>\n",
       "      <td>VLM</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>0.7285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen/Qwen3-VL-235B-A22B-Instruct</td>\n",
       "      <td>VLM</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>0.7285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mistralai/Mistral-Large-3-675B-Instruct-2512</td>\n",
       "      <td>VLM</td>\n",
       "      <td>0.4882</td>\n",
       "      <td>1.4646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>VLM</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>2.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>VLM</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemini-3-flash-preview</td>\n",
       "      <td>VLM</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gemini-3-pro-preview</td>\n",
       "      <td>VLM</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>12.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-5</td>\n",
       "      <td>VLM</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-5-mini</td>\n",
       "      <td>VLM</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-5.2</td>\n",
       "      <td>VLM</td>\n",
       "      <td>1.7500</td>\n",
       "      <td>14.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model_name model_type  input_price  \\\n",
       "0                            openai/gpt-oss-120b         LM       0.0381   \n",
       "1                           MiniMaxAI/MiniMax-M2         LM       0.1721   \n",
       "2                      deepseek-ai/DeepSeek-V3.2         LM       0.6147   \n",
       "3               Qwen/Qwen3-VL-235B-A22B-Thinking        VLM       0.2428   \n",
       "4               Qwen/Qwen3-VL-235B-A22B-Instruct        VLM       0.2428   \n",
       "5   mistralai/Mistral-Large-3-675B-Instruct-2512        VLM       0.4882   \n",
       "6                               gemini-2.5-flash        VLM       0.3000   \n",
       "7                                 gemini-2.5-pro        VLM       1.2500   \n",
       "8                         gemini-3-flash-preview        VLM       0.5000   \n",
       "9                           gemini-3-pro-preview        VLM       2.0000   \n",
       "10                                         gpt-5        VLM       1.2500   \n",
       "11                                    gpt-5-mini        VLM       0.2500   \n",
       "12                                       gpt-5.2        VLM       1.7500   \n",
       "\n",
       "    output_price  \n",
       "0         0.1143  \n",
       "1         0.5162  \n",
       "2         1.8440  \n",
       "3         0.7285  \n",
       "4         0.7285  \n",
       "5         1.4646  \n",
       "6         2.5000  \n",
       "7        10.0000  \n",
       "8         3.0000  \n",
       "9        12.0000  \n",
       "10       10.0000  \n",
       "11        2.0000  \n",
       "12       14.0000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pricing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "086d559e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating gemini-2.5-flash_2026-01-19_17-25-16\n",
      "\t- google/gemini-2.5-flash -> Total cost: $1.0914\n",
      "\t  (Input tokens: 9639, Output tokens: 66684, Reasoning tokens: 368709)\n",
      "\t- google/gemini-3-flash-preview -> Total cost: $0.2072\n",
      "\t  (Input tokens: 115245, Output tokens: 20583, Reasoning tokens: 29260)\n",
      "Total: $1.2985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"../outputs\"\n",
    "\n",
    "for eval_dir in os.listdir(root_dir):\n",
    "\tif eval_dir.startswith(\"eval_\"):\n",
    "\t\tfor model_dir in os.listdir(os.path.join(root_dir, eval_dir)):\n",
    "\t\t\tprint(f\"Evaluating {model_dir}\")\n",
    "\n",
    "\t\t\tlog_file = os.path.join(\n",
    "\t\t\t\troot_dir, eval_dir, model_dir,\n",
    "\t\t\t\t[f for f in os.listdir(os.path.join(root_dir, eval_dir, model_dir)) if f.endswith(\".eval\")][0]\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\t# Read the inspect.ai evaluation log\n",
    "\t\t\tlog = read_eval_log(log_file)\n",
    "\n",
    "\t\t\ttotal_cost = 0.0\n",
    "\t\t\tfor model_name, usage in log.stats.model_usage.items():\n",
    "\t\t\t\t# remove everything that comes before the first slash (there could be two slashes in case of huggingface models)\n",
    "\t\t\t\tcleaned_model_name = model_name.replace(model_name.split(\"/\")[0] + \"/\", \"\")\n",
    "\t\t\t\tinput_cost_per_1m_tokens = pricing_df.loc[pricing_df[\"model_name\"] == cleaned_model_name, \"input_price\"].values[0]\n",
    "\t\t\t\toutput_cost_per_1m_tokens = pricing_df.loc[pricing_df[\"model_name\"] == cleaned_model_name, \"output_price\"].values[0]\n",
    "\t\t\t\tcost = usage.input_tokens / 1_000_000 * input_cost_per_1m_tokens + (usage.output_tokens + usage.reasoning_tokens) / 1_000_000 * output_cost_per_1m_tokens\n",
    "\t\t\t\ttotal_cost += cost\n",
    "\n",
    "\t\t\t\tprint(f\"\\t- {model_name} -> Total cost: ${cost:.4f}\\n\\t  (Input tokens: {usage.input_tokens}, Output tokens: {usage.output_tokens}, Reasoning tokens: {usage.reasoning_tokens})\")\n",
    "\t\t\tprint(f\"Total: ${total_cost:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e63907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
